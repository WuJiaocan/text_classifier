{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据，包括文本和label，文本去停用词和分词之后，用不同的特征提取方式和不同的模型，测试'vect__max_df'，'vect__min_df'，'vect__ngram_range'这三个参数的最优值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = open('stop_words.txt','r',encoding='utf-8').readlines()\n",
    "stop_words = [word.strip() for word in stop_words]\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import jieba\n",
    "\n",
    "\n",
    "'''\n",
    "    加载训练数据集，并将文本分词\n",
    "'''\n",
    "data = open('train_data.txt').read()\n",
    "labels, texts, = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split(\"\\t\")\n",
    "    labels.append(content[0])\n",
    "#     texts.append(content[1])\n",
    "    text = content[1]\n",
    "    lists = []\n",
    "    for word in jieba.cut(text):\n",
    "        if word != \" \" and word not in stop_words:\n",
    "            lists.append(word)\n",
    "    texts.append(\"/\".join(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import jieba\n",
    "\n",
    "\n",
    "'''\n",
    "    加载训练数据集，并将文本分词\n",
    "'''\n",
    "data = open('36kr_format3.txt').read()\n",
    "labels1, texts1, = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split(\"\\t\")\n",
    "    labels1.append(content[0])\n",
    "#     texts.append(content[1])\n",
    "    text = content[1]\n",
    "    lists = []\n",
    "    for word in jieba.cut(text):\n",
    "        if word != \" \" and word not in stop_words:\n",
    "            lists.append(word)\n",
    "    texts1.append(\"/\".join(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    将之前的训练数据集扩充，加上所有剩下的36kr的正样本数据\n",
    "'''\n",
    "labels.extend(labels1)\n",
    "texts.extend(texts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个dataframe，列名为text和label\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4127,)\n",
      "(4127,)\n"
     ]
    }
   ],
   "source": [
    "print(trainDF['text'].shape)\n",
    "print(trainDF['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = trainDF['text']\n",
    "train_y = trainDF['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 加载测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    加载头条全部数据的前一千条，仅有context没有label，后面用阈值预测\n",
    "'''\n",
    "data = open('JinRiTouTiao_format_1000.txt')\n",
    "texts = []\n",
    "for line in data:\n",
    "    text = line.strip()\n",
    "    lists = []\n",
    "    for word in jieba.cut(text):\n",
    "        if word != \" \" and word not in stop_words:\n",
    "            lists.append(word)\n",
    "    texts.append(\"/\".join(lists))\n",
    "\n",
    "#创建一个dataframe，列名为text和label\n",
    "testDF = pandas.DataFrame()\n",
    "testDF['text'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998,)\n"
     ]
    }
   ],
   "source": [
    "print(testDF['text'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = testDF['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #将训练集分为训练集和验证集\n",
    "# from sklearn import model_selection\n",
    "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label编码为目标变量\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "train_y = encoder.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 定义调参函数\n",
    "#### model：训练数据的模型，eg: 朴素贝叶斯、逻辑回归、支持向量机、随机森林、xgboost等\n",
    "#### vect: 特征提取方式，词频或tdidf\n",
    "#### train_x: 特征\n",
    "#### train_y: 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParameter(model, vect, train_x, train_y):\n",
    "\n",
    "    from time import time\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    categories = [\n",
    "        '0',\n",
    "        '1',\n",
    "    ]\n",
    "\n",
    "    pipeline = Pipeline([ # 选择体征提取方式和模型\n",
    "        ('vect', vect),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "        ('lr', model),\n",
    "    ])\n",
    "\n",
    "\n",
    "    parameters = { # 调整的参数\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__min_df':(1, 2, 3),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 测试不同模型下的最优参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 12.874s\n",
      "Best score: 0.641\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bestParameter(MultinomialNB(), CountVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 12.663s\n",
      "Best score: 0.768\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bestParameter(MultinomialNB(), TfidfVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   22.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 23.855s\n",
      "Best score: 0.778\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bestParameter(LogisticRegression(), CountVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 15.517s\n",
      "Best score: 0.816\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bestParameter(LogisticRegression(), TfidfVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 117.010s\n",
      "Best score: 0.943\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bestParameter(LinearSVC(), CountVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 101.131s\n",
      "Best score: 0.933\n",
      "Best parameters set:\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bestParameter(LinearSVC(), TfidfVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.501s\n",
      "Best score: 0.806\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bestParameter(RandomForestClassifier(), CountVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   12.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 12.373s\n",
      "Best score: 0.790\n",
      "Best parameters set:\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bestParameter(RandomForestClassifier(), TfidfVectorizer(), train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndone in 32.667s\\nBest score: 0.808\\nBest parameters set:\\n    vect__max_df: 0.5\\n    vect__min_df: 1\\n    vect__ngram_range: (1, 1)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bestParameter(xgboost.XGBClassifier(), CountVectorizer(), train_x, train_y)\n",
    "\n",
    "'''\n",
    "done in 32.667s\n",
    "Best score: 0.808\n",
    "Best parameters set:\n",
    "    vect__max_df: 0.5\n",
    "    vect__min_df: 1\n",
    "    vect__ngram_range: (1, 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndone in 35.071s\\nBest score: 0.823\\nBest parameters set:\\n    vect__max_df: 0.75\\n    vect__min_df: 1\\n    vect__ngram_range: (1, 1)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bestParameter(xgboost.XGBClassifier(), TfidfVectorizer(), train_x, train_y)\n",
    "\n",
    "'''\n",
    "done in 35.071s\n",
    "Best score: 0.823\n",
    "Best parameters set:\n",
    "    vect__max_df: 0.75\n",
    "    vect__min_df: 1\n",
    "    vect__ngram_range: (1, 1)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
